# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "DMM_output.baml": "class Zone {\n  zone_id string\n}\n\nclass Child_Condition {\n  child_id string @description(#\"\n    the identifier of the child\n  \"#)\n  reason string @description(#\"\n    description why the child needs help\n  \"#)\n  required_MAT string @description(#\"\n    the action through which you help the child, must be one of the resolutions passed\n  \"#)\n  zone_name string @description(#\"\n    the zone where the child is located\n  \"#)\n  zone_id string @description(#\"\n    the id of the zone where the child is located\n  \"#)\n}\n\nclass Happening {\n  zone_id string @description(#\"\n    the id of the zone\n  \"#)\n  reason string @description(#\"\n    description of what is happening in the zone\n  \"#)\n  required_MAT string @description(#\"\n    the action through which you help the child, must be one of the resolutions passed\n  \"#)\n  zone_name string @description(#\"\n    the name of the zone\n  \"#)\n}\n\nclass Output {\n  type \"move\" | \"prepare\" |\"help\" @description(#\"\n    the type of action you want to take (move or prepare)\n  \"#)\n  identifier string? @description(#\"\n    the identifier of the child you want to help or the zone you want to move to\n  \"#)\n  help string? @description(#\"\n    the action through which you help a child, must be one of the resolutions passed (only needed if type is help)\n  \"#)\n}\n\nfunction Take_Action_Preschool(agent_zone: Zone, station_zones: Zone[], zone_ids: Zone[],child_conditions: Child_Condition[]?, happenings: Happening[]?) -> Output {\n    client CustomGPT4o\n    prompt #\"\n      {{ _.role(\"system\") }}\n      You are a robot that is supposed to prepare learning station in preschool.\n      You can either move to a specific zone or you can prepare a learning station.\n      In order to prepare a learning you must be in the same zone as the learning station.\n      Your goal is to prepare all learning stations as fast as possible.\n      But you should prioritize fulfilling additional obligations.\n      There are two types of obligations: helping children and keeping constraints that may arise from happenings in zones.\n      In order to help a child you must be in the same zone as the child. Otherwise, in order to help the child, you first have to move there. \n      Happenings in zones may require you to not move to a specific zone (or to exit the zone if you are already in the zone).\n\n      {{ _.role(\"user\") }}\n      Here are the ids of all zones in the preschool:\n      {{ zone_ids }}\n      You are currently at zone {{ agent_zone }}.\n      The following are the zones of the learning stations:\n      {{ station_zones }}\n      The following lists (if any) the additional obligations (children that need help alongside the zone they are in as well as the happenings in the zones):\n      {{ child_conditions }}\n      {{ happenings }}\n      Double check that your next action does not violate any of the obligations if there are any.\n      Also double check that your strategy is as efficient as possible if you concentrate on preparing learning stations (meaning you should try to minimize unnecessary movements considering your current position).\n      Also double check that if you choose to move, you specify the zone you want to move to. You can not simply \"move out of a zone\". You always have to move TO a specific zone.\n      Choose you next action and explicitly state you reasoning behind your decision. \n\n    {{ ctx.output_format }}\n    \"#\n}\n\n",
    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n    temperature 0\n  }\n}\n\nclient<llm> CustomGPT4oMini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT3Turbo {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-3.5-turbo\"\n    api_key env.OPENAI_API_KEY\n    temperature 0\n  }\n}\n\nclient<llm> CustomSonnet {\n  provider anthropic\n  options {\n    model \"claude-3-5-sonnet-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-haiku-20240307\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT4oMini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.206.1\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "resume.baml": "// Defining a data model.\nclass Resume {\n  name string\n  email string\n  experience string[]\n  skills string[]\n}\n\n// Create a function to extract the resume from a string.\nfunction ExtractResume(resume: string) -> Resume {\n  // Specify a client as provider/model-name\n  // you can use custom LLM params with a custom client name from clients.baml like \"client CustomHaiku\"\n  client \"openai/gpt-4o\" // Set OPENAI_API_KEY to use this client.\n  prompt #\"\n    Extract from this content:\n    {{ resume }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n\n\n// Test the function with a sample resume. Open the VSCode playground to run this.\ntest vaibhav_resume {\n  functions [ExtractResume]\n  args {\n    resume #\"\n      Vaibhav Gupta\n      vbv@boundaryml.com\n\n      Experience:\n      - Founder at BoundaryML\n      - CV Engineer at Google\n      - CV Engineer at Microsoft\n\n      Skills:\n      - Rust\n      - C++\n    \"#\n  }\n}\n",
}

def get_baml_files():
    return _file_map